{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import geopandas\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import seaborn\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import make_grid\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.transforms import Resize\n",
    "import fiona\n",
    "from fiona import Feature, Geometry\n",
    "from shapely.geometry import mapping, shape, Point\n",
    "import math\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False, figsize=(12,12))\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"../resources/processed/processed/part*.csv\"\n",
    "\n",
    "import glob\n",
    "filenames = glob.glob(CSV_PATH)\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(f) for f in filenames])\n",
    "df.dropna(axis=0, how=\"any\", subset=[\"ticket_id\", \"coords\", \"photo\", \"timestamp\", \"type\"], inplace=True)\n",
    "df.set_index(\"ticket_id\", inplace=True)\n",
    "df = df.convert_dtypes()\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df = df.loc[df[\"type\"].str.contains(\"จราจร\"),:]\n",
    "coord_df = df[\"coords\"].str.split(pat=\",\", n=2, expand=True)\n",
    "df[\"lat\"] = coord_df[1].astype(float)\n",
    "df[\"long\"] = coord_df[0].astype(float)\n",
    "\n",
    "df = df[[\"photo\", \"lat\", \"long\", \"timestamp\", \"type\"]]\n",
    "\n",
    "print(df.dtypes)\n",
    "print(df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "bangkok_subdistrict_df = geopandas.read_file('Bangkok-subdistricts.geojson')\n",
    "\n",
    "subdistricts = bangkok_subdistrict_df[['DNAME', 'SNAME', 'geometry']].values.tolist()\n",
    "\n",
    "def findAddress(longitude, lattitude):\n",
    "    for subdistrict in subdistricts:\n",
    "        if subdistrict[2].contains(Point(longitude, lattitude)):\n",
    "            return [subdistrict[0], subdistrict[1]]\n",
    "    return [None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_district = []\n",
    "new_subdistrict = []\n",
    "indexes = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    indexes.append(index)\n",
    "    district, subdistrict = findAddress(row[\"long\"], row[\"lat\"])\n",
    "    new_district.append(district)\n",
    "    new_subdistrict.append(subdistrict)\n",
    "\n",
    "df[\"subdistrict\"] = pd.Series(new_subdistrict, dtype=\"string\", index=indexes)\n",
    "df[\"district\"] = pd.Series(new_district, dtype=\"string\", index=indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, how=\"any\", subset=[\"subdistrict\", \"district\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)\n",
    "print(df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5x6\", pretrained=True)\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n",
    "    print(run.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = \"runs:/{}/model\".format(\"630f2cc3384544d0b4d4ccabcee2fdd9\")\n",
    "loaded_model = mlflow.pytorch.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_count = []\n",
    "indexes = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    indexes.append(index)\n",
    "    pred = model(\"../resources/photos/\" + index + \".jpg\")\n",
    "    object_counts = pred.pandas().xyxy[0].name.value_counts()\n",
    "    if \"car\" in object_counts:\n",
    "        car_count.append(object_counts[\"car\"])\n",
    "    else:\n",
    "        car_count.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"car_count\"] = pd.Series(car_count, index=indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"car_count\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"after_detect.csv\", encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./after_detect.csv\")\n",
    "df.set_index(\"ticket_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "counts = []\n",
    "resize = Resize((480, 480))\n",
    "\n",
    "start = random.randint(0, df.shape[0] - 3)\n",
    "for i in range(start, start+3):\n",
    "    images.append(resize(read_image(\"../resources/photos/\" + df.index[i] + \".jpg\")))\n",
    "    counts.append(df.iloc[i, -1])\n",
    "grid = make_grid(images, nrow=3)\n",
    "print(counts)\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkk_road_df = geopandas.read_file(\"bangkok_road.shp\", enabled_drivers=[\"ESRI Shapefile\"], encoding=\"utf-8-sig\")\n",
    "bkk_road_df = bkk_road_df[[\"osm_id\", \"geometry\"]]\n",
    "bkk_road_df[\"osm_id\"] = bkk_road_df[\"osm_id\"].astype(\"int64\")\n",
    "bkk_road_df.set_index(\"osm_id\", inplace=True)\n",
    "print(bkk_road_df.shape)\n",
    "bkk_road_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "lats = []\n",
    "lons = []\n",
    "osm_ids = []\n",
    "new_district = []\n",
    "new_subdistrict = []\n",
    "\n",
    "for row in tqdm(bkk_road_df.iterrows(), total=bkk_road_df.shape[0]):\n",
    "    for coord in row[1].geometry.coords:\n",
    "        lats.append(coord[1])\n",
    "        lons.append(coord[0])\n",
    "        osm_ids.append(row[0])\n",
    "        points.append(Point(coord[0], coord[1]))\n",
    "        district, subdistrict = findAddress(coord[0], coord[1])\n",
    "        new_district.append(district)\n",
    "        new_subdistrict.append(subdistrict)\n",
    "\n",
    "points_df = geopandas.GeoDataFrame({\"osm_id\": osm_ids, \"district\": new_district, \"subdistrict\": new_subdistrict, \"lat\": lats, \"lon\": lons}, crs=\"EPSG:4326\", geometry=points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "def get_nearest(src_points, candidates):\n",
    "    tree = BallTree(candidates, leaf_size=15, metric='haversine')\n",
    "    dist, indices = tree.query(src_points, k=1)\n",
    "    indices = indices.transpose()\n",
    "    return dist.transpose()[0], indices[0]\n",
    "\n",
    "def nearest_neighbor(left_gdf, right_gdf):\n",
    "    right = right_gdf.copy().reset_index(drop=True)\n",
    "    left_radians = np.array([(row[\"long\"] * np.pi / 180, row[\"lat\"] * np.pi / 180) for _, row in left_gdf.iterrows()])\n",
    "    right_radians = np.array(right[\"geometry\"].apply(lambda geom: (geom.x * np.pi / 180, geom.y * np.pi / 180)).to_list())\n",
    "    dist, closest = get_nearest(left_radians, right_radians)\n",
    "    closest_points = right.loc[closest]\n",
    "    closest_points[\"point_id\"] = closest\n",
    "    closest_points[\"ticket_id\"] = left_gdf.index\n",
    "    closest_points.set_index(\"ticket_id\", inplace=True)\n",
    "    return dist, closest_points\n",
    "\n",
    "traffy_point = pd.read_csv('after_detect.csv')\n",
    "\n",
    "for hour in tqdm(range(0,24)):\n",
    "    splitted = traffy_point[traffy_point['timestamp'].apply(lambda x: int(x[11:13])) == hour]\n",
    "    this_result = points_df.copy()\n",
    "    dist, closest_points = nearest_neighbor(splitted, this_result)\n",
    "    closest_points[\"car_count\"] = splitted[\"car_count\"]\n",
    "\n",
    "    closest_point_df_groupby = closest_points.groupby(by=\"point_id\")\n",
    "    closest_points = closest_points.loc[closest_point_df_groupby[\"car_count\"].idxmax()]\n",
    "    this_result[\"car_count\"] = closest_point_df_groupby[\"car_count\"].max()\n",
    "    this_result[\"is_origin\"] = this_result[\"car_count\"].notna()\n",
    "    this_result[\"car_count\"] = this_result[\"car_count\"].fillna(value=0)\n",
    "    this_result[\"car_count\"] = this_result[\"car_count\"].astype(\"int64\")\n",
    "\n",
    "    MAX_DIST = 100 # meter\n",
    "    for i, row in this_result.iterrows():\n",
    "        if (row[\"osm_id\"] in closest_points[\"osm_id\"].values):\n",
    "            all_points = closest_points[closest_points[\"osm_id\"] == row[\"osm_id\"]]\n",
    "            weighted_car_count = []\n",
    "            for i2, row2 in all_points.iterrows():\n",
    "                d = 0\n",
    "                if row[\"geometry\"] != row2[\"geometry\"]:\n",
    "                    lat1 = row[\"geometry\"].x * np.pi / 180\n",
    "                    lat2 = row2[\"geometry\"].x * np.pi / 180\n",
    "                    lon1 = row[\"geometry\"].y * np.pi / 180\n",
    "                    lon2 = row2[\"geometry\"].y * np.pi / 180\n",
    "                    angle = math.sin(lat1) * math.sin(lat2) + math.cos(lat1) * math.cos(lat2) *  math.cos(lon2-lon1)\n",
    "                    d = math.acos(angle)\n",
    "                    d *= 6371000\n",
    "                if d < MAX_DIST:\n",
    "                    weighted_car_count.append((1 - (d / MAX_DIST)) * row2[\"car_count\"])\n",
    "                else:\n",
    "                    weighted_car_count.append(0)\n",
    "            this_result.loc[i, \"car_count\"] = round(max(weighted_car_count))\n",
    "    \n",
    "    this_result\n",
    "    this_result[\"hour\"] = hour\n",
    "    this_result.drop(columns=[\"osm_id\", \"geometry\"], inplace=True)\n",
    "\n",
    "    this_result.to_csv('traffy_splitted_time' + str(hour) + '.csv', encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffy_result = pd.DataFrame()\n",
    "\n",
    "for hour in range(0, 24):\n",
    "    tmp_file = pd.read_csv('traffy_splitted_time' + str(hour) + '.csv')\n",
    "    traffy_result = pd.concat([traffy_result, tmp_file])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffy_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffy_result.drop('Unnamed: 0', axis=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffy_result.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffy_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffy_result.to_csv(\"total.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+pymysql://myadmin:Admin_123456@datasciproject.mysql.database.azure.com/traffy_project')\n",
    "traffy_result.to_sql('prediction_complete3', con = engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
